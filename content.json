{"meta":{"title":"AutuEnd's Blog","subtitle":"","description":"","author":"AutuEnd","url":"http://AutuEnd.github.io","root":"/"},"pages":[{"title":"My friend","date":"2024-05-12T03:57:32.000Z","updated":"2024-05-12T04:06:05.575Z","comments":true,"path":"PY.html","permalink":"http://autuend.github.io/PY.html","excerpt":"","text":"Hello every one…"}],"posts":[{"title":"MATH 257","slug":"MATH-257","date":"2024-05-14T05:33:43.000Z","updated":"2024-05-14T11:27:33.014Z","comments":true,"path":"2024/05/14/MATH-257/","permalink":"http://autuend.github.io/2024/05/14/MATH-257/","excerpt":"","text":"Note for MATH 257 Main question: $A\\boldsymbol x &#x3D; \\boldsymbol b$ 1 Introduction to Vectors1.1 Vectors We use $\\left[ \\begin{array}{} x\\newline y \\newline …\\end{array}\\right]$ to present an vector Linear Combinations: $3\\boldsymbol{v}+5\\boldsymbol{w}$ is a typical linear combination $c\\boldsymbol{v}+d\\boldsymbol{w}$ of the vetors $\\boldsymbol{v}$ and $\\boldsymbol{w}$ 1.2 Lengths and Dot Products Lengths: $||\\boldsymbol{v}||&#x3D;\\sqrt{\\boldsymbol v \\cdot \\boldsymbol v}&#x3D;\\sqrt{\\sum{v_i*v_i}}$ Dot product: $\\boldsymbol{v}\\cdot \\boldsymbol{w}&#x3D;\\sum{v_i*w_i}$, $\\boldsymbol{v}$ and $\\boldsymbol{w}$ have same rows. Angle: angle $\\theta$ between $\\boldsymbol v$ and $\\boldsymbol w$ has $\\cos \\theta &#x3D; \\dfrac{\\boldsymbol v \\cdot \\boldsymbol w}{||\\boldsymbol v||*||\\boldsymbol w||}$ 2 Matrics Elimination2.1 Matrix Rows and Columns: We called $A&#x3D;\\left[ \\begin{array}{}1 &amp; 2 \\newline 3 &amp; 4\\newline 5 &amp; 6\\end{array}\\right]$ a 3 by 2 ($3\\times 2$) matrix. With $m&#x3D;3$ rows and $n&#x3D;2$ columns. Multiplication: If $A\\ce{(m\\times n)}\\cdot B\\ce{(n\\times p)}&#x3D;C\\ce{(m\\times p)}$, then $c_{ij}&#x3D;\\sum_{k&#x3D;1}^{n}{a_{ik}}{b_{kj}}$ Identity Matrix: $I$, $i_{ij}&#x3D;\\begin{cases}0, ~ i\\not &#x3D;j\\newline 1, ~ i&#x3D;j\\end{cases}$ 2.2 Elimination $A\\to U$ $A &#x3D; LU &#x3D; LDU$ $U$: Upper Triangular System, All $0$ for $u_{ij}, i &gt; j$. $L$: Lower Triangular System, All $0$ for $l_{ij}, i &lt; j$. $E$: Elimination matrix, $U &#x3D; (\\prod_0^n{E_i})A$, $L &#x3D; \\prod_n^0 E_i^{-1}$ In $A &#x3D; LDU $, we riqure $u_{ii}&#x3D;l_{ii}&#x3D;1$ and $d_{ij}&#x3D;0 ~ \\ce{ for }~ i \\not &#x3D; j$ Example: $\\left[ \\begin{array}{}2 &amp; 8 \\newline 6 &amp; 29\\end{array}\\right] &#x3D; \\left[ \\begin{array}{}1 &amp; 0 \\newline 3 &amp; 1\\end{array}\\right]\\left[ \\begin{array}{}2 &amp; 8 \\newline 0 &amp; 5\\end{array}\\right] &#x3D; \\left[ \\begin{array}{}1 &amp; 0 \\newline 3 &amp; 1\\end{array}\\right]\\left[ \\begin{array}{}2 &amp; 0 \\newline 0 &amp; 5\\end{array}\\right]\\left[ \\begin{array}{}1 &amp; 4 \\newline 0 &amp; 1\\end{array}\\right]$ $E&#x3D;\\begin{bmatrix}1 &amp; 0\\newline -3 &amp; 1\\end{bmatrix}$ Augmented Matrix: $[A ~ \\boldsymbol b]&#x3D;[\\boldsymbol a_1 ~ … ~ \\boldsymbol a_n ~ \\boldsymbol b]$ Elimination of Augmented Matrix: $[A ~ \\boldsymbol b]\\to [U ~ \\boldsymbol b’]$ $A&#x3D;\\left[\\begin{array}{}3 &amp; 2 &amp; 1\\newline 2 &amp; 3 &amp; 1\\newline 1 &amp; 2 &amp; 3\\end{array}\\right]$, $\\boldsymbol b &#x3D; \\left[\\begin{array}{}39\\newline 34\\newline 26\\newline\\end{array}\\right]$ $\\left[\\begin{array}{}3 &amp; 2 &amp; 1 &amp; 39\\newline 2 &amp; 3 &amp; 1 &amp; 34\\newline 1 &amp; 2 &amp; 3 &amp; 26\\end{array}\\right]\\to \\left[\\begin{array}{}3 &amp; 2 &amp; 1 &amp; 39\\newline 0 &amp; 5&#x2F;3 &amp; 1&#x2F;3 &amp; 8\\newline 0 &amp; 0 &amp; 12&#x2F;5 &amp; 33&#x2F;5\\end{array}\\right]$ 3 Inverse &amp; Transpose3.1 Defination Inverse For a square matrix $A$, inverse matrix $A^{-1}: A^{-1}A&#x3D;I$ or $AA^{-1}&#x3D;I$ If $A$ have an $A^{-1}$, then A is invertible &#x2F; non-sigular, or A is sigular. For square $A(n\\times n)$, $A^{-1}\\iff rank(A)&#x3D;n$ Transpose $A^{T}$’s row is same as $A$’s column $(AB)^{-1}&#x3D;B^{-1}A^{-1}$ $(AB)^T&#x3D;B^TA^T$ $(A^{-1})^T&#x3D;(A^T)^{-1}$ 3.2 Calculate $A^{-1}$ Gauss-Jordan Elimination For $AA^{-1}&#x3D;I$, make an Augmented Matrix with $[A ~ I]$, make elimination to $[U ~ A^{-1}]$ Example: $\\left[\\begin{array}{}1 &amp; 3\\newline 2 &amp; 7\\end{array}\\right] A^{-1}&#x3D;\\left[\\begin{array}{}1 &amp; 0\\newline 0 &amp; 1\\end{array}\\right]$ $[A ~ I] &#x3D; \\left[\\begin{array}{}1 &amp; 3 &amp; 1 &amp; 0\\newline 2 &amp; 7 &amp; 0 &amp; 1\\end{array}\\right]$ Do Gauss Elimination to: $\\begin{bmatrix}1 &amp; 3 &amp; 1 &amp; 0\\newline 0 &amp; 1 &amp; -2 &amp; 1\\end{bmatrix}$ Do Jordan Elimination to:$\\begin{bmatrix}1 &amp; 0 &amp; 7 &amp; 3\\newline 0 &amp; 1 &amp; -2 &amp; 1\\end{bmatrix} &#x3D; [I ~ A^{-1}]$ So $A^{-1}&#x3D;\\begin{bmatrix} 7 &amp; -3\\newline -2 &amp; 1\\end{bmatrix}$ 4 Space4.1 Definition All linear combination of all vectors in Space(or Subspace) will still in Space(or subspace). $\\ce{Subspace} ~ R^m \\subset \\ce{Space} ~ R^n$, We called $R^m$ is a subspace of $R^n$, $n\\ge m$ obviously. The Space $R^n$ consists of all vectors $\\boldsymbol v$ with $n$ components $\\boldsymbol v_1, \\boldsymbol v_2, …,\\boldsymbol v_n\\in R^m$, for any $\\boldsymbol w &#x3D; \\sum_{i&#x3D;1}^n k_i \\boldsymbol v_i (k_i ~ \\ce{is any real number})$,$\\boldsymbol w\\in ~ {R^m}$. ${R^m}$ can be space or subspace. Point $[0,…,0]^T$ in any Space and any Subspace 4.2 Span The space $span{\\boldsymbol v_1, \\boldsymbol v_2, …, \\boldsymbol v_n}$ is by all linear combination of these $n$ vectors, it must be $R^n$ or a subspace of $R^n$ Example: $span{[1,1]^T,[1,1]^T}&#x3D;R^1(y&#x3D;x)$ $span{[1,1]^T,[1,2]^T}&#x3D;R^2$ 4.3 independence, basis, rank and dimension Linear independent: $\\sum{c_i\\boldsymbol{x}_i}\\not &#x3D;{0}$ for any $c_i$ with $\\prod c_i\\not &#x3D; 0$ basis: basis are linear independent. Basis is not unique. rank Defination: The rank of $A$ is the number of pivots. This number is $r$ &#x2F; $\\ce{r}(A)$ &#x2F; $\\ce{rank}(A)$. Also the dimension of $C(A)$ and $C(A^T)$. ($\\ce{rank}(A)&#x3D;\\ce{rank}(A^T)$) Pivots and Free variables: For $A ~ (n\\times m)$: The numbers of Pivots &#x3D; $\\ce{rank}(A)$ The numbers of Free variables &#x3D; $m - \\ce{rank}(A)$ dimension: $A$ has dimension $\\ce{rank}(A)$ 4.4 Spaces of Matrix Example: $A &#x3D; \\begin{bmatrix} 1 &amp; 2\\newline 2 &amp; 4\\newline 3 &amp; 5\\end{bmatrix}$ $C(A)&#x3D;\\ce{span}{[1,2,3]^T,[2,4,5]^T}$: Column Space of A $C(A)&#x3D;C([\\boldsymbol v_1, \\boldsymbol v_2, …, \\boldsymbol v_n])&#x3D;\\ce{span}{\\boldsymbol v_1, \\boldsymbol v_2, …, \\boldsymbol v_n}$ $C(A^T)&#x3D;\\ce{span}{[1,2]^T,[3,5]^T}$: Row Space of A $C(A^T)&#x3D;C(\\begin{bmatrix}-\\boldsymbol v_1-\\newline -\\boldsymbol v_2-\\newline ……\\newline -\\boldsymbol v_n-\\end{bmatrix})&#x3D;\\ce{span}{\\boldsymbol v_1, \\boldsymbol v_2, …, \\boldsymbol v_n}$ $N(A)&#x3D;R^0$: Nullspace of A All solutions $\\boldsymbol x$ to $A\\boldsymbol{x}&#x3D;0$ $N(A^T)&#x3D;\\ce{span}{[-2,1,0]^T}$: Left Nullspace of A All solutions $\\boldsymbol x$ to $A^T\\boldsymbol{x}&#x3D;0$ For $A(n\\times m)$, $\\begin{cases} \\ce{rank}(C(A))+\\ce{rank}(N(A^T))&#x3D;n, C(A)\\perp N(A^T)\\newline \\ce{rank}(C(A^T))+\\ce{rank}(N(A))&#x3D;m, C(A^T)\\perp N(A)\\end{cases}$ 4.5 Solve $A \\boldsymbol x &#x3D; \\boldsymbol b$ First, solve $A \\boldsymbol x &#x3D; \\boldsymbol 0~(N(A))$ $R$: Reduced Row Echelon form $R &#x3D; \\ce{rref}(A)$ $N(A)&#x3D;N(U)&#x3D;N(R)$ has all pivots &#x3D; $1$, with zeros above and below We can use Elimination or $R$ to solve it. Then, solve $A \\boldsymbol x &#x3D; \\boldsymbol b$ $\\boldsymbol{x}{complete}&#x3D;\\boldsymbol{x}{particular}+\\ce{any linear combination of N(A)}$","categories":[],"tags":[{"name":"MATH 257","slug":"MATH-257","permalink":"http://autuend.github.io/tags/MATH-257/"}]},{"title":"MATH 221/231/241 Notes (Updating)","slug":"Calculus Note","date":"2024-05-12T04:13:15.328Z","updated":"2024-05-12T08:31:35.383Z","comments":true,"path":"2024/05/12/Calculus Note/","permalink":"http://autuend.github.io/2024/05/12/Calculus%20Note/","excerpt":"","text":"limitation Derivation ，， ，， ， ， ， ， ， Integration Applications of Integrals Area : Arc Length : Area of a Surface of Revolution : Approximate Integration For all: Midpoint Rule and Trapezoidal Rule Simpson’s Rule , Series TestsTests Intergral Test Let Then Comparison Test Limit Comparison Test When: Then: &amp; Ratio Test Alternating Series Test Root Test Taylo For all : For :","categories":[],"tags":[{"name":"MATH","slug":"MATH","permalink":"http://autuend.github.io/tags/MATH/"}]},{"title":"Hello World","slug":"hello-world","date":"2024-05-11T10:35:25.774Z","updated":"2024-05-11T10:35:25.774Z","comments":true,"path":"2024/05/11/hello-world/","permalink":"http://autuend.github.io/2024/05/11/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"MATH 257","slug":"MATH-257","permalink":"http://autuend.github.io/tags/MATH-257/"},{"name":"MATH","slug":"MATH","permalink":"http://autuend.github.io/tags/MATH/"}]}